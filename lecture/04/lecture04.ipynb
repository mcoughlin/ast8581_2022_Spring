{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 1920, 'height': 1080, 'scroll': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1920,\n",
    "        'height': 1080,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 03 (Monday), AST 8581 / PHYS 8581 / CSCI 8581: Big Data in Astrophysics\n",
    "\n",
    "### Michael Coughlin <cough052@umn.edu>, Michael Steinbach <stei0062@umn.edu>, Nico Adams adams900@umn.edu\n",
    "\n",
    "\n",
    "With contributions totally ripped off from Zjelko Ivezic and Mario Juric (UW), Gordon Richards (Drexel), Federica Bianco (U. Del), Maria Suveges (EPFL), Gautham Narayan (UIUC), Michael Steinbach (UMN) and Nico Adams (UMN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Homework # 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### - Really nice work, and interesting to see the ways folks solved the problems!\n",
    "\n",
    "* Thank you everyone who stuck to the structure. Gentle reminder to use 01/homework01.ipynb, 02/homework02.ipynb, etc. in your folders for easy grading.\n",
    "* Please remember to make comments on the data / result when asked for it. It's OK if you don't see much or don't understand (for example, we will pick up the astro stuff as we go!), saying that is fine. - Also, please remember to use proper labels on the axes of your plots... this is good practice! - And if you are plotting magnitudes, remember to flip axes\n",
    "* I do suggest using Markdown instead of code comments for the prose... easier to see!\n",
    "* Gentle reminder to list your collaborators as well (apart from general sharing in Slack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Finishing Lecture 3 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### M-estimators and The Likelihood Function\n",
    "\n",
    "If we know the distribution from which our data were drawn (or make a hypothesis about it), then we can compute the **probability** of our data being generated.\n",
    "\n",
    "For example, for the Gaussian distribution probablity of getting a specific value of $x$ is given by:\n",
    "\n",
    "## $$p(x|\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Likelihood Function\n",
    "\n",
    "If we want to know the total probability of our *entire* data set (as opposed to one measurement) then we must compute the *product* of all the individual probabilities:\n",
    "\n",
    "## $$L \\equiv p(\\{x_i\\}|H(\\theta)) = \\prod_{i=1}^n p(x_i|H(\\theta)),$$\n",
    "\n",
    "where $H$ refers to the *hypothesis* and $\\theta$ refers collectively to the $k$ parameters of the model, which can generally be multi-dimensional. \n",
    "\n",
    "\n",
    "In words, this is ***the probability of the data given the model parameters***. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The argument of the exponential is just\n",
    "\n",
    "### $$\\exp \\left(-\\frac{\\chi^2}{2}\\right).$$\n",
    "\n",
    "where, for our Gaussian distribution\n",
    "### $$\\chi^2 = \\sum_{i=1}^n \\left ( \\frac{x_i-\\mu}{\\sigma}\\right)^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "At some specific values of the model parameters, $\\theta$, we can evaluate the likelihood of our data, given the model (you did this with the sum of squared residuals) i.e \n",
    "\n",
    "### $$p(D | \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Note**\n",
    "\n",
    "For multidimensional distributions, as we will see later in the course, the uncertainties come in the form of a covariance matrix where there uncertainties can be correlated. This still assumes Gaussianity\n",
    "\n",
    "## $$ L = p(D\\; | \\;  \\pmb \\theta\\;) =  \\prod_{k=1}^{n} \\; \\frac{1}{(2\\pi)^{d/2} \\; |\\Sigma|^{1/2}} exp \\bigg[ -\\frac{1}{2}(\\pmb x - \\pmb \\mu)^t \\Sigma^{-1}(\\pmb x - \\pmb \\mu) \\bigg]$$\n",
    "\n",
    "where $\\Sigma$ is the covariance matrix and $d$ is the dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We then determine the maximum in the same way that we always do.  It is the parameter set for which the derivative of ${\\rm lnL}$ is zero:\n",
    "\n",
    "$$\\frac{d\\;{\\rm lnL}(\\mu)}{d\\mu}\\Biggr\\rvert_{\\hat \\mu} \\equiv 0.$$\n",
    "\n",
    "That gives $$ \\sum_{i=1}^N \\frac{(x_i - \\hat \\mu)}{\\sigma^2} = 0.$$\n",
    "\n",
    "(note: we should also check that the $2^{\\rm nd}$ derivative is negative, to ensure this is the *maximum* of $L$)\n",
    "\n",
    "(also note: any constants in $\\ln L$ disappear when differentiated, so constant terms can typically be ignored.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, maximizing the likelihood is the same as minimizing $\\chi^2$:\n",
    "\n",
    "Maximizing the likelihood is solving for the extremum of:\n",
    "### $$ L \\sim \\exp \\left(-\\frac{\\chi^2}{2}\\right).$$\n",
    "\n",
    "is the same as Maximizing the natural logarithm of the likelihood:\n",
    "(because the log is a monotonically increasing function)\n",
    "\n",
    "### $$ \\ln (L) \\sim -\\frac{\\chi^2}{2}$$\n",
    "\n",
    "and therefore is the same as **minimizing** the negative log likelihood:\n",
    "\n",
    "### $$ -\\ln(L) \\sim \\frac{\\chi^2}{2}$$\n",
    "\n",
    "\n",
    "i.e. maximum likelihood estimation - and $\\chi^2$ minimization are just a special case of M-estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Core Idea Behind Maximum Likelihood Estimators\n",
    "\n",
    "Let's say that we know that some data were drawn from a Gaussian distribution, but we don't know the $\\theta = (\\mu,\\sigma)$ values of that distribution (i.e., the parameters).\n",
    "\n",
    "Then Maximum Likelihood Estimation method tells us to think of the likelihood as a ***function of the unknown model parameters***, and ***find those that maximize the value of $L$***. Those will be our Maximum Likelihood Estimators for for the true values of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Properties of ML Estimators\n",
    "\n",
    "Assuming the data truly are drawn from the model, ML estimators have the following useful properties:\n",
    "\n",
    "* **They are consistent estimators**; that is, they can be proven to converge to the true parameter value as the number of data points increases.\n",
    "\n",
    "* **They are asymptotically normal estimators**. The distribution of the parameter estimate, as the number of data points increases to infinity, approaches a normal distribution, centered at the MLE, with a certain spread. \n",
    "\n",
    "* **This spread can often be easily calculated and used as a confidence band around the estimate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Quantifying Estimate Uncertainty\n",
    "\n",
    "We *define* the uncertainty on our MLEs using the second (partial) derivatives of log-likelihood:\n",
    "\n",
    "## $$\\sigma_{jk} = \\left( - \\frac{d^2}{d\\theta_j} \\frac{\\ln L}{d\\theta_k} \\Biggr\\rvert_{\\theta=\\hat \\theta}\\right)^{-1/2}.$$\n",
    "\n",
    "Taken together, these entries (more accurately, their squares) are know as the **covariance matrix**. We'd defined this in terms on samples from a bivariate distribution last week. Now we're redefining it in terms of the likelihood!\n",
    "\n",
    "This is also called the **Fisher-information matrix, $I(\\theta)$** \n",
    "\n",
    "The marginal error bars for each parameter, $\\theta_i$ are given by the diagonal elements, $\\sigma_{ii}$. These are the \"error bars\" that are typically quoted with each measurement. Off diagonal elements, $\\sigma_{ij}$, arise from any correlation between the parameters in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our example with Gaussian likelihoods, the uncertainly on the mean is \n",
    "## $$\\sigma_{\\mu} = \\left( - \\frac{d^2\\ln L(\\mu)}{d\\mu^2}\\Biggr\\rvert_{\\hat \\mu}\\right)^{-1/2}$$\n",
    "\n",
    "We find\n",
    "## $$\\frac{d^2\\ln L(\\mu)}{d\\mu^2}\\Biggr\\rvert_{\\hat \\mu} = - \\sum_{i=1}^N\\frac{1}{\\sigma^2} = -\\frac{N}{\\sigma^2},$$\n",
    "since, again, $\\sigma = {\\rm constant}$.  \n",
    "\n",
    "Then \n",
    "## $$\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{N}}.$$\n",
    "\n",
    "So, our estimator of $\\mu$ is $\\overline{x}\\pm\\frac{\\sigma}{\\sqrt{N}}$, which is a result that you should be familiar with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Goodness of Fit\n",
    "\n",
    "The MLE approach tells us what the \"best\" model parameters are, but not how good the fit actually is.  \n",
    "(You already know the MLE estimate can be poor if there are outliers).\n",
    "\n",
    "If the model is wrong, \"best\" might not be particularly revealing!  \n",
    "\n",
    "We can describe the **goodness of fit** as whether or not it is likely to have obtained $\\ln L_0$ by randomly drawing from the data.  That means that we need to know the *distribution* of $\\ln L$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![Ivezic, Figure 4.1](http://www.astroml.org/_images/fig_chi2_eval_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "* Describing random variables\n",
    "    * null hypothesis rejection testing\n",
    "    * outlier rejection with $\\sigma$-clipping and robust statistics\n",
    "* M-estimators and maximum likelihood\n",
    "    * HW includes using Huber loss as a robust M-estimator\n",
    "* Goodness of fit\n",
    "\n",
    "\n",
    "# <center> It's fine if the last two items seem vague - we've got all this week on maximum likelihood! </center>\n",
    "\n",
    "### <center> Other things we should talk more about? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/nhrt_key.png\"> \n",
    "Courtesy Federica Bianco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But there are some natural questions that arise:\n",
    "\n",
    "* How do you know you specified the right model if you can't rule it out with the observations?\n",
    "* How do you know you had enough data to estimate the parameters of the model robustly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Big Picture: What Are We After?\n",
    "\n",
    "There are two fundamental types of statistical questions we want to answer:\n",
    "\n",
    "#### 1. Model Selection\n",
    "\n",
    "*Given two potential Models, which better describes my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Is there a linear trend in this data?\n",
    "- Does a linear or quadratic fit describe our data better?\n",
    "- Is there a periodic signal in this timeseries?\n",
    "- Does this star have a planet around it? Does this star have two planets around it?\n",
    "\n",
    "Often one of the two models is a *null hypothesis*, or a baseline model in which the effect you're interested in is not observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2. Model Fitting\n",
    "*Given this Model, what parameters best fit my data?*\n",
    "\n",
    "Examples:\n",
    "\n",
    "- What are the slope and intercept of a line of best-fit?\n",
    "- What are the parameters of the best quadratic fit?\n",
    "- What is the frequency, amplitude, and phase of a sinusoidal fit?\n",
    "- What are the orbital parameters of a planet in this radial velocity data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Simply, how confident are you in your model itself?\n",
    "\n",
    "#### This is on the surface a straightforward question, but it leads to a deep philosophical split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Frequentism\n",
    "\n",
    "In this view of the Universe, there is some underlying truth.\n",
    "\n",
    "I want the photon flux F from a given star, then measure it again, then again, and so on, each time I will get a slightly different answer due to the statistical error of my measuring device.\n",
    "\n",
    "In the limit of a large number of measurements, the frequency of any given value indicates the probability of measuring that value.\n",
    "\n",
    "For *frequentists*, probabilities are fundamentally related to frequencies of events i.e. **$P(D|H)$**.\n",
    "\n",
    "This means, for example, that in a strict frequentist view, it is meaningless to talk about the probability of the true flux of the star: the true flux is (by definition) a single fixed value. \n",
    "\n",
    "To talk about a frequency distribution for a fixed value or model parameter is nonsense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img align=\"left\" src=\"figures/41114_2018_17_Fig4_HTML.png\" width=\"400px\">\n",
    "\n",
    "### Let's look at an actual example from the literature\n",
    "\n",
    "Fig 4: These plots illustrate the differences between $\\Lambda$CDM and Galileon models (see Sect. 7.3.1), with (**GN: Solid lines**) and without massive neutrinos (**GN: Dashed lines**). The Galileon models have background Friedmann equations that contain a scalar-field energy density contribution that generates late time cosmic acceleration and has an evolution consistent with observations and thus similar to that of a $\\Lambda$CDM model.\n",
    "\n",
    "The Top: CMB temperature power spectra showing the ISW effect at low multipoles. \n",
    "\n",
    "Middle: CMB lensing potential spectra. Bottom: linear matter power spectra. The models plotted in dashed lines indicate **their best fit models to Ade et al. (2014c) temperature data, WMAP9 polarization data (Hinshaw et al. 2013), and Planck-2013 CMB lensing (Ade et al. 2014d).** \n",
    "\n",
    "https://link.springer.com/article/10.1007/s41114-018-0017-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The thing to note here is that there is a model that has been \"fit\" to some noisy data, but the model is taken as \"Truth.\" \n",
    "\n",
    "# There is no uncertainty reported about the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"build/7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Bayesian View\n",
    "\n",
    "For Bayesians, the concept of probability is extended to cover degrees of certainty about statements. \n",
    "\n",
    "Say a Bayesian claims to measure the flux F of a star with some probability P(F): that probability can certainly be estimated from frequencies in the limit of a large number of repeated experiments, but this is not fundamental. \n",
    "\n",
    "The probability is a statement of my knowledge of what the measurement result will be. \n",
    "\n",
    "For Bayesians, probabilities are fundamentally related to our own knowledge about an event. \n",
    "\n",
    "This means, for example, that in a Bayesian view, we can meaningfully talk about the probability that the true flux of a star lies in a given range. \n",
    "\n",
    "That probability codifies our knowledge of the value based on prior information and/or available data i.e. **$P(H|D)$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For more a more fleshed-out discussion of these different definitions and their consequences, you can see Jake VanderPlas' [series of blog posts](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) on the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The two quantities, $P(H|D)$ and $P(D|H)$ are related to each other by Bayes' rule:\n",
    "\n",
    "# $$ P(H|D) \\propto P(D|H) \\cdot P(H) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Wherefore the Controversy?\n",
    "\n",
    "When we write Bayes' rule this way, we're all of a sudden doing something controversial: can you see where this controversy lies?\n",
    "\n",
    "Two controversial points:\n",
    "\n",
    "- We have a probability distribution over model parameters. A frequentist would say this is meaningless!\n",
    "\n",
    "- The answer depends on the prior $P(H)$. This is the probability of the model without any data: how are we supposed to know that?\n",
    "\n",
    "Nevertheless, applying Bayes' rule in this manner gives us a means of quantifying our knowledge of the parameters $\\theta$ of some hypothesis $H$ given observed data $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is the Point?\n",
    "\n",
    "At first blush, this might all seem needlessly complicated. Why not simply maximize the likelihood and be done with it? Why multiply by a prior at all?\n",
    "\n",
    "There are a couple good reasons to go through all of this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### \"Purity\"\n",
    "\n",
    "Many advocates of the Bayesian approach argue for it's philosophical purity: you quantify knowledge in terms of a probability, then follow the math to compute the answer.\n",
    "\n",
    "The fact that you need to specify a prior might be inconvenient, but we can't simply pretend it away.\n",
    "\n",
    "There are good reasons to think that the Bayesian posterior is just the quantity we wish to compute; in that case we should compute it, however inconvenient.\n",
    "\n",
    "Perhaps the most vocal 20th century proponent of this view was Jaynes; I'd highly suggest looking at his book, *Probability Theory: The Logic of Science* ([PDF here](http://bayes.wustl.edu/etj/prob/book.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Parameter Uncertainties\n",
    "\n",
    "Whether frequentist or Bayesian, the maximum likelihood \"point estimate\" is only a small part of the picture. What we're really interested in scientifically is the *uncertainty* of the estimates. So simply reporting a point estimate is not appropriate.\n",
    "\n",
    "In frequentist approaches, \"error bars\" are generally computed from *Confidence Intervals*, which effectively measure $P(\\hat\\theta\\mid\\theta)$, rather than $P(\\theta\\mid D)$.\n",
    "It takes some mental gymnastics to relate the confidence interval to the quantity we as scientists have in mind when we say \"uncertainty\".\n",
    "\n",
    "In the Bayesian approach, we are actually measuring $P(\\theta\\mid D)$ from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For some approachable reading on frequentist vs. Bayesian uncertainties, I'd suggest [The Fallacy of Placing Confidence in Confidence Intervals](http://learnbayes.org/papers/confidenceIntervalsFallacy/), as well as Jake's (rather opinionated) blog post on the topic, [Confidence, Credibility, and why Frequentism and Science do not Mix](http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside - the denominator in Bayes' rule\n",
    "\n",
    "\n",
    "The denominator in Bayes' rule is the Evidence $P(D)$\n",
    "\n",
    "# $$ P(H|D) = \\frac{P(D|H) \\cdot P(H)}{P(D)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider that the evidence can be expressed as an integral using the identities we covered above:\n",
    "$$\n",
    "P(D) = \\int P(D\\mid\\theta) P(\\theta) d\\theta\n",
    "$$\n",
    "\n",
    "In other words, it is the integral over the likelihood for *all possible values of theta*.\n",
    "\n",
    "This means we could have called the Fully Marginalized Likelihood (FML) instead of the evidence. \n",
    "\n",
    "When your likelihood is a complicated function of many parameters, computing this integral can become extremely costly (a manifestation of the *curse of dimensionality*), which makes the acronym doubly appropriate in any situation where you actually need it.\n",
    "\n",
    "\n",
    "In general, for **model fitting**, you can ignore the FML as a simple normalization term. In **model selection**, the FML can become important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moving beyond this controversy requires at least one thing:\n",
    "\n",
    "If you have a \"flat\" or uniformative prior:\n",
    "\n",
    "$$ P(H) = 1$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$ P(H|D) \\propto P(D|H) $$\n",
    "\n",
    "\n",
    "But you already know that $P(D|H)$ is just the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The liklihood function then has to play a dual role:\n",
    "    \n",
    "Given a fixed set of model parameters ($\\theta = \\theta_0$) it is evaluating how likely the data you observed is.\n",
    "\n",
    "\n",
    "But, you can also consider the likelihood to be a function of the model parameters, given fixed data - we did this last week, deriving the MLE estimate for a homoscedastic Gaussian $N(\\mu,\\sigma)$.\n",
    "\n",
    "You cast the likelihood as a function you evaluated at a range of model parameter values.\n",
    "\n",
    "You'll also have to do this on your homework, except now you've got more than 1 parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confidence Interval vs. Credible Region\n",
    "\n",
    "Even with a flat uniform prior, the two approaches **are not the same.**\n",
    "\n",
    "In the **frequentist paradigm**, the meaning of the *confidence interval* $\\mu_0 \\pm \\sigma_{\\mu}$ is \n",
    "the interval that would contain the true $\\mu$ (from which the data were drawn) in 68% cases\n",
    "of a large number of imaginary repeated experiments (each with a different N values of $\\{x_i\\}$). \n",
    "\n",
    "The same interval follows from the **Bayesian approach** with uniform priors.\n",
    "However, the meaning of that so-called *credible region* is *fundamentally different*: it is the interval\n",
    "that contains the true $\\mu$ with a probability of 68%, given the given dataset (our dear one and only \n",
    "dataset - there are no imaginary experiments in Bayesian paradigm). \n",
    "\n",
    "This credible region is the relevant quantity in the context of scientific measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Essence of the Bayesian Method \n",
    "\n",
    "The basic premise of the Bayesian method is that probability statements are not limited to data, \n",
    "but can be made for model parameters and models themselves. Inferences are made by producing \n",
    "probability density functions (pdfs); most notably, **model parameters are treated as random variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In class exercise:\n",
    "\n",
    "Seeing the drawback of an MLE approach, when you fail to incorporate prior information is easy.\n",
    "\n",
    "Let's do it with some example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# some imports we need\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import scipy.integrate as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### Let's draw a homoscedastic sample of {x_i} from a Gaussian and see what happens with L\n",
    "# first generate a sample of N points drawn from N(mu,sigma):\n",
    "\n",
    "np.random.seed(42)\n",
    "sampleSize=100\n",
    "mu = 1.0\n",
    "sigma = 0.2 \n",
    "sample = st.norm(mu, sigma).rvs(sampleSize) \n",
    "\n",
    "# now compute likelihoods for each point using true mu \n",
    "muGrid = np.linspace(0,2,1000)\n",
    "likelihood = np.ones(len(muGrid))\n",
    "\n",
    "# what's the total likelihood and where is the maximum likelihood?\n",
    "for i in sample:\n",
    "    pass\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# renormalize the total area\n",
    "\n",
    "# plot the likelihood  \n",
    "    \n",
    "# plot the truth for comparison\n",
    "# you should be able to change the sample size in the above cell \n",
    "# and see the total likelihood get sharper as the sample size increases\n",
    "# you can even verify that the standard deviation scales as sqrt(N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# now what happens if I tell you that mu>=0.99?\n",
    "muMin = 0.99\n",
    "\n",
    "# draw sample as before\n",
    "np.random.seed(42)\n",
    "sampleSize=10\n",
    "mu = 1.0\n",
    "sigma = 0.2 \n",
    "sample = st.norm(mu, sigma).rvs(sampleSize)\n",
    "\n",
    "# lets clip samples to be greater than 0.99\n",
    "sample = np.clip(sample, muMin, None)\n",
    "\n",
    "likelihood = np.ones(len(muGrid))\n",
    "# what's the total likelihood and where is the maximum likelihood?\n",
    "for i in sample:\n",
    "    pass\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# renormalize the total area\n",
    "\n",
    "# plot the likelihood  \n",
    "    \n",
    "# plot the truth for comparison\n",
    "# you should be able to change the sample size in the above cell \n",
    "# and see the total likelihood get sharper as the sample size increases\n",
    "# you can even verify that the standard deviation scales as sqrt(N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice that the shape of the likelihood and posterior distributions is now quite different\n",
    "\n",
    "# with a large number of samples, this difference should be minimized... but sometimes you don't get lucky enough to get a large number of samples and still have to account for some sort of selection effect.\n",
    "\n",
    "# Here we're seeing how the distributions look different. In the homework for this week, you'll quantify how the two different frameworks can differ *quantitatively*."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
